{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from posthook import execute_posthook\n",
    "execute_posthook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faang_stock_market_prices import get_faang_historical_prices\n",
    "from database_handler import create_connection\n",
    "from datetime import datetime\n",
    "from lookups import CHROME_EXECUTOR\n",
    "\n",
    "etl_date = datetime(2023,10,23)\n",
    "db_session = create_connection()\n",
    "get_usa_webscrapping_data(db_session,etl_datetime=etl_date,does_etl_exists=True,chrome_exec_path = CHROME_EXECUTOR.PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest_datetime\n",
      "2007-01-01 00:00:00\n",
      "latest_datetime after processing 2007-01-01 00:00:00\n",
      "latest_date after conversion\n",
      "2007-01-01\n",
      "end_date_str after conversion\n",
      "2009-12-31\n",
      "getting data for  META\n",
      "{'META': {'eventsData': {}}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive\\Documents\\SE_Factory\\FSD\\Final_Project\\usa_recession_analysis\\main_notebook.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Documents/SE_Factory/FSD/Final_Project/usa_recession_analysis/main_notebook.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mprint\u001b[39m(historical_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Documents/SE_Factory/FSD/Final_Project/usa_recession_analysis/main_notebook.ipynb#W3sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39mif\u001b[39;00m historical_data[ticker]:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Documents/SE_Factory/FSD/Final_Project/usa_recession_analysis/main_notebook.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         data[ticker] \u001b[39m=\u001b[39m historical_data[ticker][\u001b[39m'\u001b[39;49m\u001b[39mprices\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Documents/SE_Factory/FSD/Final_Project/usa_recession_analysis/main_notebook.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         \u001b[39mprint\u001b[39m(data[ticker])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/Documents/SE_Factory/FSD/Final_Project/usa_recession_analysis/main_notebook.ipynb#W3sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# print(date)\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prices'"
     ]
    }
   ],
   "source": [
    "from yahoofinancials import YahooFinancials\n",
    "from database_handler import create_connection\n",
    "from faang_stock_market_prices import get_latest_datetime_from_stock_price_table,convert_local_to_utc\n",
    "from database_handler import execute_query,return_query,parse_date_columns\n",
    "from pandas_data_handler import return_create_statement_from_df,return_insert_into_sql_statement_from_df\n",
    "from datetime import datetime \n",
    "\n",
    "from lookups import DestinationDatabase\n",
    "import pandas as pd\n",
    "dst_schema = DestinationDatabase.SCHEMA_NAME.value\n",
    "# etl_datetime = datetime(2023,10,23)\n",
    "\n",
    "def create_staging_table(db_session,staging_df,schema_name,table_title):\n",
    "\n",
    "    create_stmt = return_create_statement_from_df(dataframe= staging_df,schema_name = schema_name,table_name= table_title)\n",
    "    execute_query(db_session=db_session, query= create_stmt)\n",
    "\n",
    "def store_into_staging_table(db_session,staging_df,dst_schema,dst_table):\n",
    "\n",
    "    if len(staging_df):\n",
    "        insert_stmt = return_insert_into_sql_statement_from_df(staging_df,dst_schema, dst_table)\n",
    "        execute_query(db_session=db_session, query= insert_stmt)\n",
    "    \n",
    "\n",
    "\n",
    "db_session = create_connection()\n",
    "# latest_datetime = get_latest_datetime_from_stock_price_table(db_session,dst_schema)\n",
    "latest_datetime = datetime(2007,1,1)\n",
    "print(\"latest_datetime\")\n",
    "print(latest_datetime)\n",
    "if not latest_datetime:\n",
    "    latest_datetime = convert_local_to_utc(etl_datetime)\n",
    "\n",
    "\n",
    "print(\"latest_datetime after processing\",latest_datetime)\n",
    "if latest_datetime.weekday() == 5:\n",
    "    latest_datetime += timedelta(days=1)\n",
    "# latest_date_utc = convert_local_to_utc(latest_datetime)\n",
    "\n",
    "latest_date_str = latest_datetime.strftime('%Y-%m-%d')\n",
    "print('latest_date after conversion')\n",
    "print(latest_date_str)\n",
    "\n",
    "end_datetime = convert_local_to_utc(datetime.today())\n",
    "# end_datetime = convert_local_to_utc(datetime(2010,1,1))\n",
    "end_date_str = end_datetime.strftime('%Y-%m-%d')\n",
    "\n",
    "print('end_date_str after conversion')\n",
    "print(end_date_str)\n",
    "\n",
    "# tickers = ['META','AMZN','AAPL','NFLX','GOOGL']\n",
    "tickers = ['META']\n",
    "data = {}\n",
    "for ticker in tickers:\n",
    "    yahoo_financials = YahooFinancials(ticker)\n",
    "    print(\"getting data for \",ticker)\n",
    "    historical_data = yahoo_financials.get_historical_price_data(latest_date_str, end_date_str, \"daily\")\n",
    "    print(historical_data)\n",
    "    if historical_data[ticker]:\n",
    "        data[ticker] = historical_data[ticker]['prices']\n",
    "        print(data[ticker])\n",
    "# print(date)\n",
    "for ticker, prices in data.items():\n",
    "    df = pd.DataFrame(prices)\n",
    "    parse_date_columns(df)\n",
    "    df = df.drop('date', axis=1).set_index('formatted_date')\n",
    "    df['volume'] = df['volume'].astype(float)\n",
    "    df.dropna(inplace=True)\n",
    "    print(df)\n",
    "    # source = 'yahoo_finance'\n",
    "    # df_name = ticker + '_stock_price'\n",
    "    # dst_table = f\"stg_{source}_{df_name}\"\n",
    "    # create_staging_table(db_session = db_session,staging_df = df,schema_name =dst_schema,table_title = dst_table)\n",
    "    # store_into_staging_table(db_session = db_session, staging_df = df, dst_schema = dst_schema ,dst_table = dst_table)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscrape import get_finviz_news_webscrapping_data\n",
    "from database_handler import create_connection\n",
    "from datetime import datetime\n",
    "df = get_finviz_news_webscrapping_data(create_connection(),datetime(2008,1,1),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_analysis import get_data_from_staging_table,analyze_sentiment\n",
    "from lookups import FinvizWebScrape,DestinationDatabase,PoliticianSpeeches\n",
    "from database_handler import create_connection\n",
    "resource = PoliticianSpeeches  \n",
    "df = get_data_from_staging_table(create_connection(), columns=resource.COLUMNS_NAME, source_name=resource.SOURCE,\n",
    "                                         table_title=resource.TABLE_TITLE, destination_schema_name=DestinationDatabase.SCHEMA_NAME)\n",
    "analyze_sentiment(df,resource.SOURCE,resource.TEXT_COLUMN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdp_arima_predict import get_forecast_gdp\n",
    "from lookups import FredEconomicDataWebScrape,DestinationDatabase\n",
    "from database_handler import create_connection\n",
    "from hook import create_and_store_into_fact_table\n",
    "df =get_forecast_gdp(create_connection())\n",
    "# create_and_store_into_fact_table(create_connection(),df_title,DestinationDatabase.SCHEMA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Documents\\SE_Factory\\FSD\\Final_Project\\usa_recession_analysis\\database_handler.py:64: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return_dataframe = pd.read_sql_query(con= db_session, sql= file_executor)\n"
     ]
    }
   ],
   "source": [
    "from sentiment_analysis import get_sentiment_analysis_results\n",
    "from database_handler import create_connection\n",
    "from lookups import FinvizWebScrape\n",
    "df = get_sentiment_analysis_results(create_connection(),resources=[FinvizWebScrape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker_title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>META-Meta, CME Lead Top Stocks Breaking Out With This Bullish Trait</th>\n",
       "      <td>META</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>Meta, CME Lead Top Stocks Breaking Out With Th...</td>\n",
       "      <td>Meta, CME Lead Top Stocks Breaking Out With Th...</td>\n",
       "      <td>https://finance.yahoo.com/m/9e64308e-f93d-3c47...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>META-Does ad-free Instagram mean the era of data harvesting is over?</th>\n",
       "      <td>META</td>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>Does ad-free Instagram mean the era of data ha...</td>\n",
       "      <td>Does ad-free Instagram mean the era of data ha...</td>\n",
       "      <td>https://finance.yahoo.com/m/45d331ee-e14f-3de2...</td>\n",
       "      <td>-0.4134</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>-0.1427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ticker        date  \\\n",
       "ticker_title                                                            \n",
       "META-Meta, CME Lead Top Stocks Breaking Out Wit...   META  2023-10-07   \n",
       "META-Does ad-free Instagram mean the era of dat...   META  2023-10-07   \n",
       "\n",
       "                                                        time  \\\n",
       "ticker_title                                                   \n",
       "META-Meta, CME Lead Top Stocks Breaking Out Wit...  08:00:00   \n",
       "META-Does ad-free Instagram mean the era of dat...  03:00:00   \n",
       "\n",
       "                                                                                                title  \\\n",
       "ticker_title                                                                                            \n",
       "META-Meta, CME Lead Top Stocks Breaking Out Wit...  Meta, CME Lead Top Stocks Breaking Out With Th...   \n",
       "META-Does ad-free Instagram mean the era of dat...  Does ad-free Instagram mean the era of data ha...   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "ticker_title                                                                                            \n",
       "META-Meta, CME Lead Top Stocks Breaking Out Wit...  Meta, CME Lead Top Stocks Breaking Out With Th...   \n",
       "META-Does ad-free Instagram mean the era of dat...  Does ad-free Instagram mean the era of data ha...   \n",
       "\n",
       "                                                                                                  url  \\\n",
       "ticker_title                                                                                            \n",
       "META-Meta, CME Lead Top Stocks Breaking Out Wit...  https://finance.yahoo.com/m/9e64308e-f93d-3c47...   \n",
       "META-Does ad-free Instagram mean the era of dat...  https://finance.yahoo.com/m/45d331ee-e14f-3de2...   \n",
       "\n",
       "                                                       neg     neu     pos  \\\n",
       "ticker_title                                                                 \n",
       "META-Meta, CME Lead Top Stocks Breaking Out Wit...  0.0000  0.6190  0.3810   \n",
       "META-Does ad-free Instagram mean the era of dat... -0.4134  0.0618  0.3105   \n",
       "\n",
       "                                                    compound  \n",
       "ticker_title                                                  \n",
       "META-Meta, CME Lead Top Stocks Breaking Out Wit...    0.6249  \n",
       "META-Does ad-free Instagram mean the era of dat...   -0.1427  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscrape import get_usa_webscrapping_data,get_states_webscraping_data,get_finviz_news_webscrapping_data,get_politician_speeches\n",
    "from database_handler import create_connection\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "get_usa_webscrapping_data(create_connection(),datetime(2023, 10,14),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Creating an index using the 'Name' column\n",
    "df.set_index('Name', inplace=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUICK DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscrape import get_politician_speeches\n",
    "from database_handler import create_connection\n",
    "from datetime import datetime\n",
    "from sentiment_analysis import store_sentiment_analysis_into_fact_table\n",
    "from lookups import PoliticianSpeeches\n",
    "df = get_politician_speeches(db_session=create_connection(),etl_datetime=datetime(2007,1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import urlparse\n",
    "from urllib.error import HTTPError\n",
    "from lookups import FinvizWebScrape, ErrorHandling,DestinationDatabase,FredEconomicDataWebScrape,PoliticianSpeeches\n",
    "from datetime import datetime,timedelta\n",
    "from logging_handler import show_error_message\n",
    "from pandas_data_handler import return_create_statement_from_df,return_insert_into_sql_statement_from_df,download_webscrape_csv_to_dataframe\n",
    "from database_handler import execute_query,return_query,create_connection\n",
    "from misc_handler import create_sql_table_index\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\")\n",
    "inner_driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "url = 'https://millercenter.org/the-presidency/presidential-speeches/august-28-2008-acceptance-speech-democratic-national'\n",
    "inner_driver.get(url)\n",
    "response = requests.get(url)\n",
    "\n",
    "max_wait_time = 10\n",
    "schema_name = DestinationDatabase.SCHEMA_NAME.value\n",
    "source_title = PoliticianSpeeches.SOURCE.value\n",
    "table_title = PoliticianSpeeches.TABLE_TITLE.value\n",
    "table_name = f\"stg_{source_title}_{table_title}\"\n",
    "\n",
    "if response.status_code == 200:\n",
    "    speech_title = 'August 28, 2008: Acceptance Speech at the Democratic National Convention'\n",
    "    df = pd.DataFrame()\n",
    "    speech_datetime = pd.to_datetime(speech_title.split(':')[0])\n",
    "    df['date'] = [speech_datetime]\n",
    "    df['speech_title'] = [speech_title.split(':')[1]]\n",
    "    # WebDriverWait(inner_driver, max_wait_time).until(\n",
    "    #     EC.presence_of_element_located((By.CLASS_NAME, \"transcript-btn-inner\"))\n",
    "    # )\n",
    "\n",
    "    # transcript_button = WebDriverWait(inner_driver, max_wait_time).until(\n",
    "    #     EC.element_to_be_clickable((By.CLASS_NAME, \"transcript-btn-inner\"))\n",
    "    # )\n",
    "    # time.sleep(2)\n",
    "\n",
    "    # transcript_button.click()\n",
    "\n",
    "    df['speaker_name'] = ['Barack Obama']\n",
    "\n",
    "    transcript_text = WebDriverWait(inner_driver, max_wait_time).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"view-transcript\"))\n",
    "    )\n",
    "    \n",
    "    paragraphs = transcript_text.find_elements(By.TAG_NAME, 'p')\n",
    "    text = ''\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        text+=paragraph.text + '\\n'\n",
    "    \n",
    "    df['speech'] = [text]\n",
    "    insert_stmt = return_insert_into_sql_statement_from_df(df,schema_name,table_name,is_upsert=True)\n",
    "    execute_query(create_connection(),insert_stmt)\n",
    "else:\n",
    "    error_string_prefix = ErrorHandling.WEBSCRAPE_PAGE_FAILED.value\n",
    "    error_string_suffix = f\"Unable to web scrape {inner_url}, HTTP status code: \" +response.getcode()\n",
    "    show_error_message(error_string_prefix,error_string_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_analysis import preprocess_text\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# vader.polarity_scores(preprocess_text(df['speech'][0]))\n",
    "scores = df['speech'].apply(preprocess_text).apply(\n",
    "        vader.polarity_scores).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df\n",
    "# scores_df.index.name = \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['neg','neu','pos','compound']] = scores_df[['neg','neu','pos','compound']]\n",
    "\n",
    "df['neg'] = scores_df['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['date'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df.join(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.merge(df, scores_df, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames\n",
    "data1 = {\n",
    "    ('A', 'one'): [1, 2, 3],\n",
    "    ('A', 'two'): [4, 5, 6],\n",
    "    ('B', 'one'): [7, 8, 9],\n",
    "    ('B', 'two'): [10, 11, 12],\n",
    "}\n",
    "df1 = pd.DataFrame(data1, index=['X', 'Y', 'Z'])\n",
    "\n",
    "data2 = {\n",
    "    'C': [13, 14, 15],\n",
    "    'D': [16, 17, 18],\n",
    "}\n",
    "df2 = pd.DataFrame(data2, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# Join on the index (assuming the index is common between the two DataFrames)\n",
    "result = df1.join(df2)\n",
    "\n",
    "# If the columns you want to join on are not the index, you can use the 'on' parameter\n",
    "# For example, if the common column is 'key_column':\n",
    "# result = df1.join(df2.set_index('key_column'), on=('A', 'one'))\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoofinancials import YahooFinancials\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, time,timedelta\n",
    "import pytz\n",
    "\n",
    "# tickers = ['META','AMZN','AAPL','NFLX','GOOGL']\n",
    "tickers = ['AMZN']\n",
    "\n",
    "start_date = date(2023,10,11)\n",
    "start_date = start_date.strftime('%Y-%m-%d')\n",
    "print(\"start_date\")\n",
    "print(start_date)\n",
    "end_date = datetime.today() + timedelta(days=1)\n",
    "end_date = end_date.strftime('%Y-%m-%d')\n",
    "print(\"end_date\")\n",
    "print(end_date)\n",
    "data = {}\n",
    "for ticker in tickers:\n",
    "    yahoo_financials = YahooFinancials(ticker)\n",
    "    historical_data = yahoo_financials.get_historical_price_data(start_date, end_date, \"daily\")\n",
    "    if historical_data[ticker]:\n",
    "        data[ticker] = historical_data[ticker]['prices']\n",
    "dfs = []\n",
    "titles = []\n",
    "for ticker, prices in data.items():\n",
    "    df = pd.DataFrame(prices)\n",
    "    # parse_date_columns(df)\n",
    "    df = df.drop('date', axis=1).set_index('formatted_date')\n",
    "    df['volume'] = df['volume'].astype(float)\n",
    "    # title = f'{get_coin_name(ticker[:-4])}_historical_price'\n",
    "    # titles.append(title)\n",
    "    dfs.append(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_handler import create_connection\n",
    "from webscrape import get_last_news_date\n",
    "db_session = create_connection()\n",
    "\n",
    "get_last_news_date(db_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.strptime('2023-01-01', '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webscrape import get_states_webscrape_data_from_fred_economic\n",
    "from datetime import datetime\n",
    "db_session = create_connection()\n",
    "get_states_webscrape_data_from_fred_economic(db_session,datetime(2007,1,1),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.today()\n",
    "print(end_date)\n",
    "local_tz = pytz.timezone('Asia/Beirut')\n",
    "utc_datetime = local_tz.localize(end_date).astimezone(pytz.UTC)\n",
    "print(utc_datetime)\n",
    "utc_date = utc_datetime.date()\n",
    "utc_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.today().date().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_handler import return_query,create_connection\n",
    "db_session = create_connection()\n",
    "query = \"\"\"SELECT EXISTS (\n",
    "   SELECT 1\n",
    "   FROM information_schema.tables\n",
    "   WHERE table_schema = 'dw_reporting'\n",
    "     AND table_name = 'dim_faang_stock_price'\n",
    ");\"\"\"\n",
    "return_query(db_session = db_session,query =  query)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date_query = f\"\"\"\n",
    "SELECT\n",
    "    MAX(formatted_date)\n",
    "FROM dw_reporting.dim_faang_stock_price\n",
    "\"\"\"\n",
    "latest_date = return_query(db_session = db_session,query = latest_date_query)[0][0]\n",
    "latest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "latest_date+ timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = scrape_website(etl_date= datetime(2023, 10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "President            object\n",
       "Date         datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to generate quarterly dates within a given range\n",
    "def generate_quarterly_dates(start_date, end_date):\n",
    "    return pd.date_range(start=start_date, end=end_date, freq='Q')\n",
    "\n",
    "# Create a data frame to hold the president names and dates\n",
    "president_dates = pd.DataFrame({\n",
    "    'President': [\"George W. Bush\", \"Barack Obama\", \"Donald Trump\", \"Joe Biden\"],\n",
    "    'Start_Date': pd.to_datetime([\"2001-01-20\", \"2009-01-20\", \"2017-01-20\", \"2021-01-20\"]),\n",
    "    'End_Date': pd.to_datetime([\"2009-01-20\", \"2017-01-20\", \"2021-01-20\", datetime.today()])\n",
    "})\n",
    "\n",
    "# Create an empty data frame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each president's term\n",
    "for i in range(len(president_dates)):\n",
    "    president_name = president_dates['President'][i]\n",
    "    start_date = president_dates['Start_Date'][i]\n",
    "    end_date = president_dates['End_Date'][i]\n",
    "\n",
    "    # Generate quarterly dates within the president's term\n",
    "    quarterly_dates = generate_quarterly_dates(start_date, end_date)\n",
    "\n",
    "    # Create a data frame for the current president\n",
    "    president_df = pd.DataFrame({\n",
    "        'President': [president_name] * len(quarterly_dates),\n",
    "        'Date': quarterly_dates\n",
    "    })\n",
    "\n",
    "    # Append the data for the current president to the result data frame\n",
    "    result_df = pd.concat([result_df, president_df], ignore_index=True)\n",
    "\n",
    "# result_df['Date'] = pd.to_datetime(result_df['Date'])\n",
    "# Output the result data frame\n",
    "result_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "President            object\n",
       "Date         datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to generate quarterly dates within a given range\n",
    "def generate_quarterly_dates(start_date, end_date):\n",
    "    return pd.date_range(start=start_date, end=end_date, freq='Q')\n",
    "\n",
    "# Create a data frame to hold the president names and dates\n",
    "president_dates = pd.DataFrame({\n",
    "    'President': [\"George W. Bush\", \"Barack Obama\", \"Donald Trump\", \"Joe Biden\"],\n",
    "    'Start_Date': pd.to_datetime([\"2001-01-20\", \"2009-01-20\", \"2017-01-20\", \"2021-01-20\"]),\n",
    "    'End_Date': pd.to_datetime([\"2009-01-20\", \"2017-01-20\", \"2021-01-20\", datetime.today()])\n",
    "})\n",
    "\n",
    "# Create an empty data frame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each president's term\n",
    "for i in range(len(president_dates)):\n",
    "    president_name = president_dates['President'][i]\n",
    "    start_date = president_dates['Start_Date'][i]\n",
    "    end_date = president_dates['End_Date'][i]\n",
    "\n",
    "    # Generate quarterly dates within the president's term\n",
    "    quarterly_dates = generate_quarterly_dates(start_date, end_date)\n",
    "\n",
    "    # Create a data frame for the current president\n",
    "    president_df = pd.DataFrame({\n",
    "        'President': [president_name] * len(quarterly_dates),\n",
    "        'Date': quarterly_dates\n",
    "    })\n",
    "\n",
    "    # Append the data for the current president to the result data frame\n",
    "    result_df = pd.concat([result_df, president_df], ignore_index=True)\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "result_df['Date'] = pd.to_datetime(result_df['Date'])\n",
    "\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sefactory_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
